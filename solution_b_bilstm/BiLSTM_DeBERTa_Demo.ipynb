{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ldx0fHZgB3h"
      },
      "source": [
        "### Setting up and retrieving data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvkvDLA9gB3k"
      },
      "source": [
        "#### Imports\n",
        "Performing the necessary imports for the file to run. Main imports that are used are as follows:\n",
        "- pandas/numpy: Working with data\n",
        "- transformers: BERT Tokenizer\n",
        "- sklearn: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sXW2alqilxI9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jczMstIegB3m"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "LSTM_UNITS = 64\n",
        "\n",
        "# Set a seed to decrease randomness\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Set the model file to refer to\n",
        "MODEL_NAME = 'microsoft/deberta-v3-base'\n",
        "TOKENIZER_NAME = 'bilstm.deberta-v3-base.tokenizer.json'\n",
        "SAVED_NAME = 'bilstm.deberta.keras'\n",
        "WEIGHTS_FILE = 'deberta-v3-base.weights.h5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bV5mGdKgB3m"
      },
      "source": [
        "#### Load CSV files\n",
        "Loading CSV files from test csv for preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n1mjRBSUgB3n"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmw9q_c0gB3n"
      },
      "source": [
        "#### Set up BERT-based Tokenizer\n",
        "Instantiates the tokenizer based on the model name above and define functions for encoding sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO_wfandmuC-",
        "outputId": "f56aeeb1-ef6d-46f9-998a-badad6f184de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Instantiate Tokenizer on MODEL_NAME (BERT)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Encodes sentence\n",
        "def encode_sentence(s):\n",
        "   tokens = list(tokenizer.tokenize(s))\n",
        "   tokens.append('[SEP]')\n",
        "   return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "# Encode data for the bert model with a max length of MAX_SEQUENCE_LENGTH\n",
        "def bert_encode(hypotheses, premises, tokenizer, max_length=MAX_SEQUENCE_LENGTH):\n",
        "\n",
        "    x = tokenizer(hypotheses, premises, padding='max_length', truncation=True, max_length=max_length)\n",
        "\n",
        "    inputs = {\n",
        "          'input_word_ids':tf.ragged.constant(x['input_ids']).to_tensor(),\n",
        "          'input_mask': tf.ragged.constant(x['attention_mask']).to_tensor(),\n",
        "          'input_type_ids': tf.ragged.constant(x['token_type_ids']).to_tensor()}\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D8JC4_92yHEU"
      },
      "outputs": [],
      "source": [
        "test_input = bert_encode(test.premise.values.tolist(), test.hypothesis.values.tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "WjDP9Cl7bT2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = \"0\"\n",
        "\n",
        "# Define function to build the model\n",
        "def build_model():\n",
        "    # BERT encoder layer that is non-trainable\n",
        "    bert_encoder = TFAutoModel.from_pretrained(MODEL_NAME, trainable=False)\n",
        "\n",
        "    # Tokenized input sequence (word indices), Mask to indicate real tokens/padding, Type Ids\n",
        "    input_word_ids = tf.keras.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name=\"input_mask\")\n",
        "    input_type_ids = tf.keras.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name=\"input_type_ids\")\n",
        "\n",
        "    # Encodes all 3 inputs\n",
        "    output = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]\n",
        "\n",
        "    # BiLSTM layer and normalisation to prevent overfitting.\n",
        "    output = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_UNITS))(output)\n",
        "    output = tf.keras.layers.BatchNormalization()(output)\n",
        "    output = tf.keras.layers.Dropout(0.1)(output)\n",
        "    output = tf.keras.layers.Dense(64, activation='relu')(output)\n",
        "    output = tf.keras.layers.BatchNormalization()(output)\n",
        "    output = tf.keras.layers.Dropout(0.1)(output)\n",
        "\n",
        "    # Output layer\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "    # Returns the model\n",
        "    return tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)"
      ],
      "metadata": {
        "id": "MOW_m7lNbVky"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Builds the model\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-mjYbP3obmIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fd4b6e-c8f6-4802-d19f-095b5fa3a0df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFDebertaV2Model.\n",
            "\n",
            "All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer  [(None, 100)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)     [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " input_type_ids (InputLayer  [(None, 100)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf_deberta_v2_model_1 (TFD  TFBaseModelOutput(last_hid   1838315   ['input_word_ids[0][0]',      \n",
            " ebertaV2Model)              den_state=(None, 100, 768)   52         'input_mask[0][0]',          \n",
            "                             , hidden_states=None, atte              'input_type_ids[0][0]']      \n",
            "                             ntions=None)                                                         \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 128)                  426496    ['tf_deberta_v2_model_1[0][0]'\n",
            " onal)                                                              ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 128)                  512       ['bidirectional_1[0][0]']     \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64)                   8256      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 64)                   256       ['dense_2[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64)                   0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    65        ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 184267137 (702.92 MB)\n",
            "Trainable params: 435201 (1.66 MB)\n",
            "Non-trainable params: 183831936 (701.26 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiles the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xz0K8Ebgb8PC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up Early Stopping with callback to checkpoint for the training of the model which monitors val loss\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
        "checkpoint_filepath = WEIGHTS_FILE\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "UARhCBunb-bJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Weights\n",
        "model.load_weights(WEIGHTS_FILE)"
      ],
      "metadata": {
        "id": "ngZzD4kBb_2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46f6f82-78a1-440e-9a83-00ac3944c529"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 29 variables. \n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
            "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCHcYnaagB3q"
      },
      "source": [
        "### Predicting using the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ju1IPf6vBeoz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d190a22-2b30-45d1-b9b9-a3c039bad091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104/104 [==============================] - 1779s 17s/step\n"
          ]
        }
      ],
      "source": [
        "# Use the model to predict the valid input\n",
        "outputs = model.predict(test_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "83R5WbOxKbxO"
      },
      "outputs": [],
      "source": [
        "# Convert probabilities to classes and reshape\n",
        "preds = (outputs > 0.5).astype(int)\n",
        "\n",
        "# Save predictions to CSV\n",
        "df_predictions = pd.DataFrame(preds, columns=['prediction'])\n",
        "df_predictions.to_csv(\"Group_70_B.csv\", index=False)\n",
        "\n",
        "# Get Labels for prediction\n",
        "# labels = test.label.values.reshape(-1,1)\n",
        "\n",
        "# Evaluate results\n",
        "# print(f\"Accuracy: {accuracy_score(labels, preds):.4f}\")\n",
        "# print(f\"F1 Score: {f1_score(labels, preds):.4f}\")\n",
        "# print(f\"Precision: {precision_score(labels, preds):.4f}\")\n",
        "# print(f\"Recall: {recall_score(labels, preds):.4f}\")\n",
        "# print(f\"MCC: {matthews_corrcoef(labels, preds):.4f}\")\n",
        "# print(f\"ROC AUC Score: {roc_auc_score(labels, preds):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}