# Repository Structure
[1] modelcards: Directory contains the model cards for both models
[2] solution_b_bilstm: Directory contains the test predictions and source code used for the training, evaluation and demo for solution B. For the demo, download the model using the link below before running source code. 
[3] solution_c_transformer: Directory contains the test predictions and source code used for the training, evaluation and demo for solution C. For the demo, download the model weights using the link below before running source code. 

# Solution B: Deep learning-based approaches that do not employ transformer architectures
## Saved Model

Download the model from below: 

-Link to be inserted-


# Solution C: Deep learning-based approaches underpinned by transformer architectures
## Model Weights

Download the model weights from below:

https://livemanchesterac-my.sharepoint.com/:u:/g/personal/steven_moussa_student_manchester_ac_uk/EUPyM4KJbp5HjRjL0Nx7mTQBN7dyBhASVVnAyWBj9lB5mQ?e=InX4qg


# Resources used

[1] https://www.kaggle.com/code/alessandrozanette/natural-language-inference-with-bert-model

[2] https://huggingface.co/

[3] https://paperswithcode.com/task/natural-language-inference